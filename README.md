# VMI_CV_AI - My Curriculum Vitae - AI aspect

```mermaid
graph TD
    A[Sporadic infos about AI since 1995] --> C[First Contact with ChatGPT in 2022]
    A --> B[Looks too complex without any reachable goals. Abandoned.]
    C --> D[Met with other guys, to discuss about the burning hot AI News]
    D --> E[Sensory overload from the news]
    E --> F[Ask for the Starting point - That was the Pytorch Lightning book]
    F --> G[Study of book]
    G --> I[I restored and developed the mainly outdated and damaged examples: base NN example, Bert, transfer learning, GAN, and so on]
    G --> H[It was too complicated for just read, so I translated it, for my own AI treasure]
    H --> G
    I --> J[Deeper understanding of the basic tools, components of AI: NN, Learning rate, Optimalisation, activation, hyperparams, convolution, attention]
    J --> K[Early 2025: Coding LLMs are incoming! Thinking, reasoning, agents, MCP-s]
    K --> L[Using Windsurf to generate an Authoring tool written in Python]
    L --> M[Generating with Windsurf an Yolo based object detection during az AI hackathon. 3000+ python codelines in 2 days]
    M --> N[After other tools migration to Roo Commander to orchestrate the algoritmic part of a Research paper - PhD publication - Projectmanagement support with AI.]    
```

## More about the AI supported project management research:
Because even Windsurf gives a proof about the ability of the LLMs to code AI model contained codes, and the existing LLM tools were not able to understand the difference between costs and invoices (!!!), I introduced the project manager colleagues that the vivid solution is an LLM with Retrieval-Augmented Generation. Let algoritms do the calculations (through prescribed rules), but rise the interface to another level with a LOCAL LLM model, that able to understand the questions, find the prescribed rule, search the datas from vectordb, and wrap the answer into a natural language answer. I suppose that the resource progress and the fails are important part of the publication. And even the abilities of the actual code generator models. Because of that, at the beginning I introduded to the AI tool the human actors. Reason is: I want to  orchestrate the work process well documentate the progress and the reasons, because it is a publication, not a product.

## Interesting infos about the SotA LLM code generators:
- Probably not the models but the background rules are the most precious part of this products.
- Most tools allowed to answer some direct question about its own architecture, until it not harms any business secret. This questions are very useful to reach better synergy with the models.
- The developer and AI must be at the same knowledge level. Generating an architecture of code, without understand the background increases some "entropy" and finally the code does not meet with the expectation, because the missing requirements are filled with some general practice.
- Very important part to give a positive feedback to the AI agents.

## My public repos about my earlier AI mockups:
- basic examples of AI models https://github.com/vmistvan/MIA_helyzet 
- speec recognition https://github.com/vmistvan/speech_recog
- short voyage into the SB3: https://github.com/vmistvan/SB3_Doc_Hun
